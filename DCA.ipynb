{
    "cells": [
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import pandas as pd\nfrom scipy.optimize import curve_fit\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os",
            "execution_count": 1,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def read_in_csv(file_path):\n    global produccion\n    \"\"\"\n    Read in the specified csv as a pandas dataframe\n    Arguments: \n        file_path: String. Path for the csv file that we want to read in\n    Outputs:\n        dataframe: Pandas dataframe.\n    \"\"\"\n    produccion=pd.read_csv(file_path,index_col=0,parse_dates=True)\n    return produccion",
            "execution_count": 10,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def hyperbolic_equation(t, qi, b, di):\n    \"\"\"\n    Hyperbolic decline curve equation\n    Arguments:\n        t: Float. Time since the well first came online, can be in various units \n        (days, months, etc) so long as they are consistent.\n        qi: Float. Initial production rate when well first came online.\n        b: Float. Hyperbolic decline constant\n        di: Float. Nominal decline rate at time t=0\n    Output: \n        Returns q, or the expected production rate at time t. Float.\n    \"\"\"\n    return qi/((1.0+b*di*t)**(1.0/b))",
            "execution_count": 11,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def exponential_equation(t, qi, di):\n    \"\"\"\n    Exponential decline curve equation\n    Arguments:\n        t: Float. Time since the well first came online, can be in various units \n        (days, months, etc) so long as they are consistent.\n        qi: Float. Initial production rate when well first came online.\n        di: Float. Nominal decline rate (constant)\n    Output: \n        Returns q, or the expected production rate at time t. Float.\n    \"\"\"\n    return qi*np.exp(-di*t)",
            "execution_count": 2,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def remove_nan_and_zeroes_from_columns(df, variable):\n    \"\"\"\n    This function cleans up a dataframe by removing rows in a specific \n    column that are null/NaN or equal to 0. This basically removes zero \n    production time periods.\n    Arguments:\n        df: Pandas dataframe.\n        variable: String. Name of the column where we want to filter out\n        NaN's or 0 values\n    Output:\n        filtered_df: Pandas dataframe. Dataframe with NaN's and zeroes filtered out of \n        the specified column\n    \"\"\"\n    filtered_df = df[(df[variable].notnull()) & (df[variable]>0)]\n    return filtered_df",
            "execution_count": 3,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def generate_time_delta_column(df, time_column, date_first_online_column):\n    \"\"\"\n    Create column for the time that a well has been online at each reading, with \n    the first non-null month in the series listed as the start of production\n    Arguments:\n        df: Pandas dataframe\n        time_column: String. Name of the column that includes the specific record date\n        that the data was taken at. Column type is pandas datetime\n        date_first_online_column: Name of the column that includes the date that the\n        well came online. Column type is pandas datetime\n    Outputs:\n        Pandas series containing the difference in days between the date the well\n        came online and the date that the data was recorded (cumulative days online)\n    \"\"\"\n    return (df[time_column]-df[date_first_online_column]).dt.days",
            "execution_count": 4,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def get_min_or_max_value_in_column_by_group(dataframe, group_by_column, calc_column, calc_type):\n    \"\"\"\n    This function obtains the min or max value for a column, with a group by applied. For example,\n    it could return the earliest (min) RecordDate for each API number in a dataframe \n    Arguments:\n        dataframe: Pandas dataframe \n        group_by_column: string. Name of column that we want to apply a group by to\n        calc_column: string. Name of the column that we want to get the aggregated max or min for\n        calc_type: string; can be either 'min' or 'max'. Defined if we want to pull the min value \n        or the max value for the aggregated column\n    Outputs:\n        value: Depends on the calc_column type.\n    \"\"\"\n    value=dataframe.groupby(group_by_column)[calc_column].transform(calc_type)\n    return value",
            "execution_count": 6,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def get_max_initial_production(df, number_first_months, variable_column, date_column):\n    \"\"\"\n    This function allows you to look at the first X months of production, and selects \n    the highest production month as max initial production\n    Arguments:\n        df: Pandas dataframe. \n        number_first_months: float. Number of months from the point the well comes online\n        to compare to get the max initial production rate qi (this looks at multiple months\n        in case there is a production ramp-up)\n        variable_column: String. Column name for the column where we're attempting to get\n        the max volume from (can be either 'Gas' or 'Oil' in this script)\n        date_column: String. Column name for the date that the data was taken at \n    \"\"\"\n    #First, sort the data frame from earliest to most recent prod date\n    df=df.sort_values(by=date_column)\n    #Pull out the first x months of production, where number_first_months is x\n    df_beginning_production=df.head(number_first_months)\n    #Return the max value in the selected variable column from the newly created \n    #df_beginning_production df\n    return df_beginning_production[variable_column].max()",
            "execution_count": 7,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def plot_actual_vs_predicted_by_equations(df, x_variable, y_variables, plot_title):\n    \"\"\"\n    This function is used to map x- and y-variables against each other\n    Arguments:\n        df: Pandas dataframe.\n        x_variable: String. Name of the column that we want to set as the \n        x-variable in the plot\n        y_variables: string (single), or list of strings (multiple). Name(s) \n        of the column(s) that we want to set as the y-variable in the plot\n    \"\"\"\n    #Plot results\n    df.plot(x=x_variable, y=y_variables, title=plot_title)\n    plt.show()",
            "execution_count": 8,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def main():\n    #Read in the monthly oil and gas data\n    file_path='master_dataframe_production.csv'\n    bakken_data=read_in_csv(file_path)\n    #Perform some data cleaning to get the columns as the right data type\n    bakken_data['ReportDate']=pd.to_datetime(bakken_data['ReportDate'])\n    #Declare the desired product that we want to curve fit for--it can either by 'Gas' or 'Oil'\n    desired_product_type='Oil'\n    #Remove all rows with null values in the desired time series column\n    bakken_data=remove_nan_and_zeroes_from_columns(bakken_data, desired_product_type)\n    #Get the earliest RecordDate for each API Number\n    bakken_data['Online_Date']= get_min_or_max_value_in_column_by_group(bakken_data, group_by_column='API_WELLNO', \n                  calc_column='ReportDate', calc_type='min')\n    #Generate column for time online delta\n    bakken_data['Days_Online']=generate_time_delta_column(bakken_data, time_column='ReportDate', \n                  date_first_online_column='Online_Date')\n    #Pull data that came online between January and June 2016\n    bakken_data_2016=bakken_data[(bakken_data.Online_Date>='2016-01-01') & (bakken_data.Online_Date<='2016-06-01')]\n    #Get a list of unique API's to loop through--these were randomly selected as examples\n    unique_well_APIs_list=[33023013930000.0, 33105039980000.0, 33105039970000.0, \n                           33013018230000.0, 33013018220000.0]\n    #Loop through each API, and perform calculations\n    for api_number in unique_well_APIs_list:\n        #Subset the dataframe by API Number\n        production_time_series=bakken_data_2016[bakken_data_2016.API_WELLNO==api_number]\n        #Get the highest value of production in the first three months of production, to use as qi value\n        qi=get_max_initial_production(production_time_series, 3, desired_product_type, 'ReportDate')\n        #Exponential curve fit the data to get best fit equation\n        popt_exp, pcov_exp=curve_fit(exponential_equation, production_time_series['Days_Online'], \n                                     production_time_series[desired_product_type],bounds=(0, [qi,20]))\n        print('Exponential Fit Curve-fitted Variables: qi='+str(popt_exp[0])+', di='+str(popt_exp[1]))\n        #Hyperbolic curve fit the data to get best fit equation\n        popt_hyp, pcov_hyp=curve_fit(hyperbolic_equation, production_time_series['Days_Online'], \n                                     production_time_series[desired_product_type],bounds=(0, [qi,2,20]))\n        print('Hyperbolic Fit Curve-fitted Variables: qi='+str(popt_hyp[0])+', b='+str(popt_hyp[1])+', di='+str(popt_hyp[2]))\n        #Exponential fit results\n        production_time_series.loc[:,'Exponential_Predicted']=exponential_equation(production_time_series['Days_Online'], \n                                  *popt_exp)\n        #Hyperbolic fit results\n        production_time_series.loc[:,'Hyperbolic_Predicted']=hyperbolic_equation(production_time_series['Days_Online'], \n                                  *popt_hyp)\n        #Declare the x- and y- variables that we want to plot against each other\n        y_variables=[desired_product_type, \"Hyperbolic_Predicted\", \"Exponential_Predicted\"]\n        x_variable='Days_Online'\n        #Create the plot title\n        plot_title=desired_product_type+' Production for Well API '+str(api_number)\n        #Plot the data to visualize the equation fit\n        plot_actual_vs_predicted_by_equations(production_time_series, x_variable, y_variables, plot_title)\n                \nif __name__== \"__main__\":\n    main()",
            "execution_count": 9,
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "NameError",
                    "evalue": "name 'read_in_csv' is not defined",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-9-b8ac6031c339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m<ipython-input-9-b8ac6031c339>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#Read in the monthly oil and gas data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfile_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'master_dataframe_production.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbakken_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_in_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#Perform some data cleaning to get the columns as the right data type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mbakken_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ReportDate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbakken_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ReportDate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'read_in_csv' is not defined"
                    ]
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.8",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}